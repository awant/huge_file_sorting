
Построчная сортировка большого текстового файла, не влезающего в память.

Для сортировки большого файла, можно разбить его на чанки (батчи) и отсортировать каждую часть отдельно. Записать их в файлы: part1, part2, ... . После - выполнить слияние из файлов (FileSorter).

Плюс в простоте подхода. Но нужно помнить, что:

* Существует ограничение на количество дескрипторов. При разбиении файла на большое количество чанков стратегия в том, чтобы запоминать смещения от начала файлов и при собирании сортированного файла каждый раз при выборе строки открывать текущий файл.

* Нет ограничения на количество символов в строке. В наихудшем случае длина строки может быть больше, чем доступная память. Таким образом, нам не удастся считать такую строку. Вообще говоря, построенное решение (FileSorter) будет работать в случае, если 2*max_len < mem. Удвоенность из-за сравнения 2 строк в памяти.

Чтобы учесть случай из последнего пункта, возмозжен следующий алгоритм (TODO):

* Пройтись по файлу и запомнить позиции на начала файлов

* Определить размер чанка, который возможно считать со всех строк файла

* Последовательно считывать куски всех предложений и сортировать их индексы

(LongLinesFileSorter)

## Скрипты

### Скрипт "generate.py" генерирует файл для сортировки.

```console
python generate.py --lines_count 100 --maxlen 100 --out file.txt
```

### Скрипт "sort_huge_file.py" сортирует переданный файл и записывает в file.txt.sorted (по умолчанию)

```console
python sort_huge_file.py --inp file.txt
```

